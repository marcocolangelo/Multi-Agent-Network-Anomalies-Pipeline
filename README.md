# Multi-Agent-Network-Anomalies-Pipeline
# Demo LLM Pipeline

Hi there! ğŸ‘‹
This project is a modern, agent-based pipeline demo for network anomaly detection powered by LLMs (LangChain + Ollama-ready). Agents are decoupled, extensible, and communicate via a minimal async event-bus. Notify, not Manager, generates your final report with real LLM reasoning.

---

## ğŸš€ Whatâ€™s Inside

- Fully modular design: each agent focuses on *one* job (processing, enrichment, validation, etc.)
- Async, event-driven "bus"â€”no agent knows implementation details of others!
- Dynamic, LLM-generated report by Notify
- GuardRail validates at multiple workflow steps, with retry; demo uses Fake LLM fallback if Ollama is down/offline
- Manager orchestrates, but does not hold business logic or data
- Entirely mock DBs and logs: rapid prototyping; easy to migrate to real storage
- Clean logging with trace IDs

---

## âš¡ï¸ Quick Start

### 1. Environment (choose one)

**venv:**
python -m venv .venv
source .venv/bin/activate # or .\.venv\Scripts\activate on Windows

**conda:**
conda create -n demo-llm-pipeline python=3.10 -y
conda activate demo-llm-pipeline

### 2. Install dependencies

pip install -r requirements.txt

### 3. (Optional) Use a real LLM via Ollama

ollama pull llama3
ollama serve

*(You can run the demo without Ollama; it uses Fake LLM fallback and will "just work" anyway.)*

### 4. Fire up the pipeline
python main.py

---

## ğŸ› ï¸ Architecture & Design Principles

- **Agents subscribe to event-topics**; all messaging is explicit, enabling easy plugging/removal.
- **Manager is stateless**, aware only of orchestration, never business rules or data.
- **GuardRail sits everywhere:** it validates data at ingest, enrichment, and before reports are committed.
- **Enrichment tasks (domain/historical) run in parallel;** manager waits for both, then passes them to Notify.
- **Notify aggregates & assembles the report, using the LLM for *true* reasoning**â€”not static strings.
- **Results committed atomically** to fake CSV; agent history is append-only.

---

## ğŸ§© Extending the Demo

- Swap `FakeListLLM` for a real LLM (Ollama or OpenAI) in config.py or agent files.
- Swap the async EventBus for Redis Streams, Kafka, RabbitMQâ€¦ with minor changes.
- Swap CSV/mock DBs for MongoDB or PostgreSQLâ€”persistence logic is already isolated!
- Add new retrievers, validators, or report styles by creating a new listener and topic.
- Add observability (Prometheus, OpenTelemetry) by wrapping the bus or agent callables.

---

## ğŸƒ Example Output

12:01:01 T-01fa435b Proc â–¶ start
12:01:01 T-01fa435b Proc â–¶ produced 3 rows
12:01:01 T-01fa435b GuardRail â–¶ INGEST_VALIDATE True
12:01:02 T-01fa435b AnomalyModel â–¶ anomaly detected
12:01:02 T-01fa435b KRetriever â–¶ context ready
12:01:02 T-01fa435b HRetriever â–¶ history ready
12:01:03 T-01fa435b Notify â–¶ Generating report with LLM
12:01:03 T-01fa435b GuardRail â–¶ REPORT_VALIDATE True
12:01:03 T-01fa435b Notify â–¶ commiting validated report
12:01:03 T-01fa435b Manager â–¶ cycle end, restart if needed

---

## ğŸ”§ Troubleshooting Tips

- If â€œOllama not reachable,â€ youâ€™re using the FakeLLM fallbackâ€”this is *OK* for demos!
- If pool_db.csv or agent_history.csv donâ€™t exist, they are created automatically.
- Everything is run locally, no cloud dependency.

---

## ğŸ¤“ Project Layout

```
app/core/ # bus and msg schema
app/agents/ # all agent logic, decoupled
app/models/ # mock anomaly detector
app/db/ # fake domain knowledge and CSVs
app/utils/ # config & logging/tracing
main.py # bootstrap & wiring
requirements.txt
README.md
```

### 5. Project structure
text
```
demo-llm-pipeline/
â”‚
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â”œâ”€â”€ bus.py                 # in-memory event bus (asyncio)
â”‚   â”‚   â””â”€â”€ messages.py            # Pydantic Msg schema
â”‚   â”‚
â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â”œâ”€â”€ config.py              # OLLAMA_MODEL/BASE_URL and future settings
â”‚   â”‚   â””â”€â”€ tracing.py             # logger + trace_id
â”‚   â”‚
â”‚   â”œâ”€â”€ db/                        # fake DB/knowledge
â”‚   â”‚   â”œâ”€â”€ domain_knowledge.json  # rule examples
â”‚   â”‚   â”œâ”€â”€ pool_db.csv            # created at runtime
â”‚   â”‚   â””â”€â”€ agent_history.csv      # (optional) created at runtime
â”‚   â”‚
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â””â”€â”€ anomaly_dummy.py       # mock anomaly detector
â”‚   â”‚
â”‚   â”œâ”€â”€ agents/                    # independent listeners
â”‚   â”‚   â”œâ”€â”€ proc.py                # preprocessing
â”‚   â”‚   â”œâ”€â”€ guardrail.py           # validation (Fake LLM by default)
â”‚   â”‚   â”œâ”€â”€ anomaly_model.py       # mock anomaly detector integration
â”‚   â”‚   â”œâ”€â”€ retriever_domain.py    # DK retriever (fake)
â”‚   â”‚   â”œâ”€â”€ retriever_history.py   # History retriever (fake)
â”‚   â”‚   â”œâ”€â”€ notify.py              # LLM-based report, validation, commit
â”‚   â”‚   â””â”€â”€ manager.py             # sequencer + plan listeners
â”‚   â”‚
â”‚   â””â”€â”€ __init__.py
â”‚
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ raw_logs_demo.txt              # optional seed logs (fallback present in main.py)
â”œâ”€â”€ main.py                        # wiring & bootstrap
â””â”€â”€ README.md
```

### 6. Run the demo
bash
python main.py
Example console output:

text
```
12:00:01 INFO  T-a1b2c3d4 Proc â–¶ start
12:00:02 INFO  T-a1b2c3d4 Proc â–¶ produced 3 rows
12:00:02 INFO  T-a1b2c3d4 GuardRail â–¶ INGEST_VALIDATE True
12:00:03 INFO  T-a1b2c3d4 AnomalyModel â–¶ anomaly detected
12:00:03 INFO  T-a1b2c3d4 KRetriever â–¶ context ready
12:00:03 INFO  T-a1b2c3d4 HRetriever â–¶ history ready
12:00:04 INFO  T-a1b2c3d4 Notify â–¶ Generating report with LLM
12:00:04 INFO  T-a1b2c3d4 GuardRail â–¶ REPORT_VALIDATE True
12:00:04 INFO  T-a1b2c3d4 Notify â–¶ commiting validated report
12:00:05 INFO  T-a1b2c3d4 Manager â–¶ cycle end, restart if needed
```
The generated (fake) report is appended to app/db/pool_db.csv.

### 7. How it works
main.py wires the event bus and subscribes each agent to a topic (role).

Proc preprocesses raw logs and publishes for validation.

GuardRail validates at multiple steps with bounded retries (demo uses Fake LLM; replace with Ollama if available).

AnomalyModel (mock) outputs zero or one anomaly.

Manager (sequencer) orchestrates: when an anomaly arrives, triggers KRetriever and HRetriever in parallel, collects their validated outputs, and then publishes to Notify.

Notify composes a final report dynamically via the LLM (LangChain + Ollama or Fake), sends it to GuardRail for final validation, and commits to pool DB / agent history, then sends ACK back to Manager.

### 8. Configuration
Change Ollama model and base URL in app/utils/config.py:

OLLAMA_MODEL = "llama3"

OLLAMA_BASE_URL = "http://localhost:11434"

Load environment variables with .env if needed.

### 9. Extending
Replace Fake LLM in guardrail.py and notify.py with real Ollama or OpenAI (langchain-openai) without changing other modules.

Swap EventBus with Redis Streams / Kafka / RabbitMQ by replacing publish/subscribe but keeping Msg schema.

Replace CSV with Mongo/PostgreSQL; the persistence code is isolated in notify.py.

Add more retrievers: just add a new topic and listener, then include it in the Manager plan and Notify prompt.

### 10. Troubleshooting
If you see â€œOllama not reachableâ€, the code uses a Fake LLM fallbackâ€”pipeline still completes.

Ensure Python 3.10+ and a clean virtual environment.

If CSV paths donâ€™t exist, they are created at runtime (inside app/db/).

### 11. License
For demo and educational purposes.
